В прошлой задаче (см. [data_2nd_task](https://github.com/akitim/Motorica_Gesture_Classification_Task/blob/main/data_2nd_task/README.md)) OMG-данные были представлены в размерностях (наблюдения, датчики, время). А целевая переменная имела размерности (наблюдения, время). Т.е. целевая переменная по одному конкретному наблюдению представляла из себя маску, в которой каждый элемент отражает, какая команда выполнялась пользователем. Индекс (позиция) элемента в маске отражает временной шаг соответствующий аналогичному временному шагу в OMG-данных.

Текущая постановка задачи отличается следующим:

- собраны данные от 3х разных "пилотов", размечено, какие данные относятся к какому пилоту;
- вместо обучающей выборки из наблюдений участникам предоставляется непрерывный массив OMG-данных и соответствующий массив с целевой переменной;
- количество уникальных жестов уменьшено;
- наблюдения в тестовых OMG-данные из себя представляют временные отрезки переменной длины, внутри которых могут совершаться жесты (один и больше), а могут и не совершаться жесты вообще;
